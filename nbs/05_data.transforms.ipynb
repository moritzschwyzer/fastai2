{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp data.transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.torch_basics import *\n",
    "from fastai2.data.core import *\n",
    "from fastai2.data.load import *\n",
    "from fastai2.data.external import *\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper functions for processing data and basic transforms\n",
    "\n",
    "> Functions for getting, splitting, and labeling data, as well as generic transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get, split, and label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For most data source creation we need functions to get a list of items, split them in to train/valid sets, and label them. fastai provides functions to make each of these steps easy (especially when combined with `fastai.data.blocks`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we'll look at functions that *get* a list of items (generally file names).\n",
    "\n",
    "We'll use *tiny MNIST* (a subset of MNIST with just two classes, `7`s and `3`s) for our examples/tests throughout this page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/home/moritz/.fastai/data/mnist_tiny/train/3'),Path('/home/moritz/.fastai/data/mnist_tiny/train/7')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "(path/'train').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _get_files(p, fs, extensions=None):\n",
    "    p = Path(p)\n",
    "    res = [p/f for f in fs if not f.startswith('.')\n",
    "           and ((not extensions) or f'.{f.split(\".\")[-1].lower()}' in extensions)]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def get_files(path, extensions=None, recurse=True, folders=None):\n",
    "    \"Get all the files in `path` with optional `extensions`, optionally with `recurse`, only in `folders`, if specified.\"\n",
    "    path = Path(path)\n",
    "    folders=L(folders)\n",
    "    extensions = setify(extensions)\n",
    "    extensions = {e.lower() for e in extensions}\n",
    "    if recurse:\n",
    "        res = []\n",
    "        for i,(p,d,f) in enumerate(os.walk(path)): # returns (dirpath, dirnames, filenames)\n",
    "            if len(folders) !=0 and i==0: d[:] = [o for o in d if o in folders]\n",
    "            else:                         d[:] = [o for o in d if not o.startswith('.')]\n",
    "            if len(folders) !=0 and i==0 and '.' not in folders: continue\n",
    "            res += _get_files(p, f, extensions)\n",
    "    else:\n",
    "        f = [o.name for o in os.scandir(path) if o.is_file()]\n",
    "        res = _get_files(path, f, extensions)\n",
    "    return L(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the most general way to grab a bunch of file names from disk. If you pass `extensions` (including the `.`) then returned file names are filtered by that list. Only those files directly in `path` are included, unless you pass `recurse`, in which case all child folders are also searched recursively. `folders` is an optional list of directories to limit the search to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#709) [Path('/home/moritz/.fastai/data/mnist_tiny/train/3/7762.png'),Path('/home/moritz/.fastai/data/mnist_tiny/train/3/8865.png'),Path('/home/moritz/.fastai/data/mnist_tiny/train/3/8012.png'),Path('/home/moritz/.fastai/data/mnist_tiny/train/3/8957.png'),Path('/home/moritz/.fastai/data/mnist_tiny/train/3/7721.png'),Path('/home/moritz/.fastai/data/mnist_tiny/train/3/8597.png'),Path('/home/moritz/.fastai/data/mnist_tiny/train/3/9637.png'),Path('/home/moritz/.fastai/data/mnist_tiny/train/3/9303.png'),Path('/home/moritz/.fastai/data/mnist_tiny/train/3/9778.png'),Path('/home/moritz/.fastai/data/mnist_tiny/train/3/8246.png')...]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3 = get_files(path/'train'/'3', extensions='.png', recurse=False)\n",
    "t7 = get_files(path/'train'/'7', extensions='.png', recurse=False)\n",
    "t  = get_files(path/'train', extensions='.png', recurse=True)\n",
    "test_eq(len(t), len(t3)+len(t7))\n",
    "test_eq(len(get_files(path/'train'/'3', extensions='.jpg', recurse=False)),0)\n",
    "test_eq(len(t), len(get_files(path, extensions='.png', recurse=True, folders='train')))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "test_eq(len(get_files(path/'train'/'3', recurse=False)),346)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders=['train', 'test'])),729)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders='train')),709)\n",
    "test_eq(len(get_files(path, extensions='.png', recurse=True, folders='training')),0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's often useful to be able to create functions with customized behavior. `fastai.data` generally uses functions named as CamelCase verbs ending in `er` to create these functions. `FileGetter` is a simple example of such a function creator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def FileGetter(suf='', extensions=None, recurse=True, folders=None):\n",
    "    \"Create `get_files` partial function that searches path suffix `suf`, only in `folders`, if specified, and passes along args\"\n",
    "    def _inner(o, extensions=extensions, recurse=recurse, folders=folders):\n",
    "        return get_files(o/suf, extensions, recurse, folders)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpng = FileGetter(extensions='.png', recurse=False)\n",
    "test_eq(len(t7), len(fpng(path/'train'/'7')))\n",
    "test_eq(len(t), len(fpng(path/'train', recurse=True)))\n",
    "fpng_r = FileGetter(extensions='.png', recurse=True)\n",
    "test_eq(len(t), len(fpng_r(path/'train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "image_extensions = set(k for k,v in mimetypes.types_map.items() if v.startswith('image/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_image_files(path, recurse=True, folders=None):\n",
    "    \"Get image files in `path` recursively, only in `folders`, if specified.\"\n",
    "    return get_files(path, extensions=image_extensions, recurse=recurse, folders=folders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is simply `get_files` called with a list of standard image extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(t), len(get_image_files(path, recurse=True, folders='train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ImageGetter(suf='', recurse=True, folders=None):\n",
    "    \"Create `get_image_files` partial function that searches path suffix `suf` and passes along `kwargs`, only in `folders`, if specified.\"\n",
    "    def _inner(o, recurse=recurse, folders=folders): return get_image_files(o/suf, recurse, folders)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as `FileGetter`, but for image extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(len(get_files(path/'train', extensions='.png', recurse=True, folders='3')),\n",
    "        len(ImageGetter(   'train',                    recurse=True, folders='3')(path)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_text_files(path, recurse=True, folders=None):\n",
    "    \"Get text files in `path` recursively, only in `folders`, if specified.\"\n",
    "    return get_files(path, extensions=['.txt'], recurse=recurse, folders=folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def ItemGetter(i):\n",
    "    \"Creates a proper transform that applies `itemgetter(i)` (even on a tuple)\"\n",
    "    return ItemTransform(itemgetter(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(ItemGetter(1)((1,2,3)),  2)\n",
    "test_eq(ItemGetter(1)(L(1,2,3)), 2)\n",
    "test_eq(ItemGetter(1)([1,2,3]),  2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next set of functions are used to *split* data into training and validation sets. The functions return two lists - a list of indices or masks for each of training and validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def RandomSplitter(valid_pct=0.2, seed=None, **kwargs):\n",
    "    \"Create function that splits `items` between train/val with `valid_pct` randomly.\"\n",
    "    def _inner(o, **kwargs):\n",
    "        if seed is not None: torch.manual_seed(seed)\n",
    "        rand_idx = L(int(i) for i in torch.randperm(len(o)))\n",
    "        cut = int(valid_pct * len(o))\n",
    "        return rand_idx[cut:],rand_idx[:cut]\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = list(range(30))\n",
    "f = RandomSplitter(seed=42)\n",
    "trn,val = f(src)\n",
    "assert 0<len(trn)<len(src)\n",
    "assert all(o not in val for o in trn)\n",
    "test_eq(len(trn), len(src)-len(val))\n",
    "# test random seed consistency\n",
    "test_eq(f(src)[0], trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use scikit-learn train_test_split. This allow to *split* items in a stratified fashion (uniformely according to the ‘labels‘ distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def TrainTestSplitter(test_size=0.2, random_state=None, stratify=None, **kwargs):\n",
    "    \"Split ‘items‘ into random train and test subsets using sklearn train_test_split utility.\"\n",
    "    def _inner(o, **kwargs):\n",
    "        train, valid = train_test_split(range(len(o)), test_size=test_size, random_state=random_state, stratify=stratify, **kwargs)\n",
    "        return L(train), L(valid)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src = list(range(30))\n",
    "labels = [0] * 20 + [1] * 10\n",
    "test_size = 0.2\n",
    "\n",
    "f = TrainTestSplitter(test_size=test_size, random_state=42, stratify=labels)\n",
    "trn,val = f(src)\n",
    "assert 0<len(trn)<len(src)\n",
    "assert all(o not in val for o in trn)\n",
    "test_eq(len(trn), len(src)-len(val))\n",
    "\n",
    "# test random seed consistency\n",
    "test_eq(f(src)[0], trn)\n",
    "\n",
    "# test labels distribution consistency\n",
    "# there should be test_size % of zeroes and ones respectively in the validation set\n",
    "test_eq(len([t for t in val if t < 20]) / 20, test_size)\n",
    "test_eq(len([t for t in val if t > 20]) / 10, test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def IndexSplitter(valid_idx):\n",
    "    \"Split `items` so that `val_idx` are in the validation set and the others in the training set\"\n",
    "    def _inner(o, **kwargs):\n",
    "        train_idx = np.setdiff1d(np.array(range_of(o)), np.array(valid_idx))\n",
    "        return L(train_idx, use_list=True), L(valid_idx, use_list=True)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(range(10))\n",
    "splitter = IndexSplitter([3,7,9])\n",
    "test_eq(splitter(items),[[0,1,2,4,5,6,8],[3,7,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def _grandparent_idxs(items, name):\n",
    "    def _inner(items, name): return mask2idxs(Path(o).parent.parent.name == name for o in items)\n",
    "    return [i for n in L(name) for i in _inner(items,n)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def GrandparentSplitter(train_name='train', valid_name='valid'):\n",
    "    \"Split `items` from the grand parent folder names (`train_name` and `valid_name`).\"\n",
    "    def _inner(o, **kwargs):\n",
    "        return _grandparent_idxs(o, train_name),_grandparent_idxs(o, valid_name)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = [path/'train/3/9932.png', path/'valid/7/7189.png', \n",
    "          path/'valid/7/7320.png', path/'train/7/9833.png',  \n",
    "          path/'train/3/7666.png', path/'valid/3/925.png',\n",
    "          path/'train/7/724.png', path/'valid/3/93055.png']\n",
    "splitter = GrandparentSplitter()\n",
    "test_eq(splitter(fnames),[[0,3,4,6],[1,2,5,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames2 = fnames + [path/'test/3/4256.png', path/'test/7/2345.png', path/'valid/7/6467.png']\n",
    "splitter = GrandparentSplitter(train_name=('train', 'valid'), valid_name='test')\n",
    "test_eq(splitter(fnames2),[[0,3,4,6,1,2,5,7,10],[8,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def FuncSplitter(func):\n",
    "    \"Split `items` by result of `func` (`True` for validation, `False` for training set).\"\n",
    "    def _inner(o, **kwargs):\n",
    "        val_idx = mask2idxs(func(o_) for o_ in o)\n",
    "        return IndexSplitter(val_idx)(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = FuncSplitter(lambda o: Path(o).parent.parent.name == 'valid')\n",
    "test_eq(splitter(fnames),[[0,3,4,6],[1,2,5,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def MaskSplitter(mask):\n",
    "    \"Split `items` depending on the value of `mask`.\"\n",
    "    def _inner(o, **kwargs): return IndexSplitter(mask2idxs(mask))(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(range(6))\n",
    "splitter = MaskSplitter([True,False,False,True,False,True])\n",
    "test_eq(splitter(items),[[1,2,4],[0,3,5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def FileSplitter(fname):\n",
    "    \"Split `items` depending on the value of `mask`.\"\n",
    "    valid = Path(fname).read().split('\\n')\n",
    "    def _func(x): return x.name in valid\n",
    "    def _inner(o, **kwargs): return FuncSplitter(_func)(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as d:\n",
    "    fname = Path(d)/'valid.txt'\n",
    "    fname.write('\\n'.join([Path(fnames[i]).name for i in [1,3,4]]))\n",
    "    splitter = FileSplitter(fname)\n",
    "    test_eq(splitter(fnames),[[0,2,5,6,7],[1,3,4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def ColSplitter(col='is_valid'):\n",
    "    \"Split `items` (supposed to be a dataframe) by value in `col`\"\n",
    "    def _inner(o, **kwargs):\n",
    "        assert isinstance(o, pd.DataFrame), \"ColSplitter only works when your items are a pandas DataFrame\"\n",
    "        valid_idx = o[col].values\n",
    "        return IndexSplitter(mask2idxs(valid_idx))(o)\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a': [0,1,2,3,4], 'b': [True,False,True,True,False]})\n",
    "splits = ColSplitter('b')(df)\n",
    "test_eq(splits, [[1,4], [0,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def RandomSubsetSplitter(train_sz, valid_sz, seed=None):\n",
    "    \"Take randoms subsets of `splits` with `train_sz` and `valid_sz`\"\n",
    "    assert 0 < train_sz < 1\n",
    "    assert 0 < valid_sz < 1\n",
    "    assert train_sz + valid_sz <= 1.\n",
    "\n",
    "    def _inner(o, **kwargs):\n",
    "        if seed is not None: torch.manual_seed(seed)\n",
    "        train_len,valid_len = int(len(o)*train_sz),int(len(o)*valid_sz)\n",
    "        idxs = L(int(i) for i in torch.randperm(len(o)))\n",
    "        return idxs[:train_len],idxs[train_len:train_len+valid_len]\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = list(range(100))\n",
    "valid_idx = list(np.arange(70,100))\n",
    "splits = RandomSubsetSplitter(0.3, 0.1)(items)\n",
    "test_eq(len(splits[0]), 30)\n",
    "test_eq(len(splits[1]), 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final set of functions is used to *label* a single item of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def parent_label(o, **kwargs):\n",
    "    \"Label `item` with the parent folder name.\"\n",
    "    return Path(o).parent.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that `parent_label` doesn't have anything customize, so it doesn't return a function - you can just use it directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eq(parent_label(fnames[0]), '3')\n",
    "test_eq(parent_label(\"fastai_dev/dev/data/mnist_tiny/train/3/9932.png\"), '3')\n",
    "[parent_label(o) for o in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test for MS Windows when os.path.sep is '\\\\' instead of '/'\n",
    "test_eq(parent_label(os.path.join(\"fastai_dev\",\"dev\",\"data\",\"mnist_tiny\",\"train\", \"3\", \"9932.png\") ), '3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class RegexLabeller():\n",
    "    \"Label `item` with regex `pat`.\"\n",
    "    def __init__(self, pat, match=False):\n",
    "        self.pat = re.compile(pat)\n",
    "        self.matcher = self.pat.match if match else self.pat.search\n",
    "\n",
    "    def __call__(self, o, **kwargs):\n",
    "        res = self.matcher(str(o))\n",
    "        assert res,f'Failed to find \"{self.pat}\" in \"{o}\"'\n",
    "        return res.group(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`RegexLabeller` is a very flexible function since it handles any regex search of the stringified item. Pass `match=True` to use `re.match` (i.e. check only start of string), or `re.search` otherwise (default).\n",
    "\n",
    "For instance, here's an example the replicates the previous `parent_label` results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3', '7', '7', '7', '3', '3', '7', '3']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = RegexLabeller(fr'{os.path.sep}(\\d){os.path.sep}')\n",
    "test_eq(f(fnames[0]), '3')\n",
    "[f(o) for o in fnames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = RegexLabeller(r'(\\d*)', match=True)\n",
    "test_eq(f(fnames[0].name), '9932')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ColReader():\n",
    "    \"Read `cols` in `row` with potential `pref` and `suff`\"\n",
    "    def __init__(self, cols, pref='', suff='', label_delim=None):\n",
    "        store_attr(self, 'suff,label_delim')\n",
    "        self.pref = str(pref) + os.path.sep if isinstance(pref, Path) else pref\n",
    "        self.cols = L(cols)\n",
    "\n",
    "    def _do_one(self, r, c):\n",
    "        o = r[c] if isinstance(c, int) else getattr(r, c)\n",
    "        if len(self.pref)==0 and len(self.suff)==0 and self.label_delim is None: return o\n",
    "        if self.label_delim is None: return f'{self.pref}{o}{self.suff}'\n",
    "        else: return o.split(self.label_delim) if len(o)>0 else []\n",
    "\n",
    "    def __call__(self, o, **kwargs): \n",
    "        if len(self.cols) == 1: return self._do_one(o, self.cols[0])\n",
    "        return L(self._do_one(o, c) for c in self.cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`cols` can be a list of column names or a list of indices (or a mix of both). If `label_delim` is passed, the result is split using it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'a': 'a b c d'.split(), 'b': ['1 2', '0', '', '1 2 3']})\n",
    "f = ColReader('a', pref='0', suff='1')\n",
    "test_eq([f(o) for o in df.itertuples()], '0a1 0b1 0c1 0d1'.split())\n",
    "\n",
    "f = ColReader('b', label_delim=' ')\n",
    "test_eq([f(o) for o in df.itertuples()], [['1', '2'], ['0'], [], ['1', '2', '3']])\n",
    "\n",
    "df['a1'] = df['a']\n",
    "f = ColReader(['a', 'a1'], pref='0', suff='1')\n",
    "test_eq([f(o) for o in df.itertuples()], [L('0a1', '0a1'), L('0b1', '0b1'), L('0c1', '0c1'), L('0d1', '0d1')])\n",
    "\n",
    "df = pd.DataFrame({'a': [L(0,1), L(2,3,4), L(5,6,7)]})\n",
    "f = ColReader('a')\n",
    "test_eq([f(o) for o in df.itertuples()], [L(0,1), L(2,3,4), L(5,6,7)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class CategoryMap(CollBase):\n",
    "    \"Collection of categories with the reverse mapping in `o2i`\"\n",
    "    def __init__(self, col, sort=True, add_na=False):\n",
    "        if is_categorical_dtype(col): items = L(col.cat.categories, use_list=True)\n",
    "        else:\n",
    "            if not hasattr(col,'unique'): col = L(col, use_list=True)\n",
    "            # `o==o` is the generalized definition of non-NaN used by Pandas\n",
    "            items = L(o for o in col.unique() if o==o)\n",
    "            if sort: items = items.sorted()\n",
    "        self.items = '#na#' + items if add_na else items\n",
    "        self.o2i = defaultdict(int, self.items.val2idx()) if add_na else dict(self.items.val2idx())\n",
    "    def __eq__(self,b): return all_equal(b,self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap([4,2,3,4])\n",
    "test_eq(t, [2,3,4])\n",
    "test_eq(t.o2i, {2:0,3:1,4:2})\n",
    "test_fail(lambda: t.o2i['unseen label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap([4,2,3,4], add_na=True)\n",
    "test_eq(t, ['#na#',2,3,4])\n",
    "test_eq(t.o2i, {'#na#':0,2:1,3:2,4:3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = CategoryMap(pd.Series([4,2,3,4]), sort=False)\n",
    "test_eq(t, [4,2,3])\n",
    "test_eq(t.o2i, {4:0,2:1,3:2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = pd.Series(pd.Categorical(['M','H','L','M'], categories=['H','M','L'], ordered=True))\n",
    "t = CategoryMap(col)\n",
    "test_eq(t, ['H','M','L'])\n",
    "test_eq(t.o2i, {'H':0,'M':1,'L':2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class Categorize(Transform):\n",
    "    \"Reversible transform of category string to `vocab` id\"\n",
    "    loss_func,order=CrossEntropyLossFlat(),1\n",
    "    def __init__(self, vocab=None, add_na=False):\n",
    "        self.add_na = add_na\n",
    "        self.vocab = None if vocab is None else CategoryMap(vocab, add_na=add_na)\n",
    "\n",
    "    def setups(self, dsets):\n",
    "        if self.vocab is None and dsets is not None: self.vocab = CategoryMap(dsets, add_na=self.add_na)\n",
    "        self.c = len(self.vocab)\n",
    "\n",
    "    def encodes(self, o): return TensorCategory(self.vocab.o2i[o])\n",
    "    def decodes(self, o): return Category      (self.vocab    [o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Category(str, ShowTitle): _show_args = {'label': 'category'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorize()\n",
    "tds = Datasets(['cat', 'dog', 'cat'], tfms=[cat])\n",
    "test_eq(cat.vocab, ['cat', 'dog'])\n",
    "test_eq(cat('cat'), 0)\n",
    "test_eq(cat.decode(1), 'dog')\n",
    "test_stdout(lambda: show_at(tds,2), 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = Categorize(add_na=True)\n",
    "tds = Datasets(['cat', 'dog', 'cat'], tfms=[cat])\n",
    "test_eq(cat.vocab, ['#na#', 'cat', 'dog'])\n",
    "test_eq(cat('cat'), 1)\n",
    "test_eq(cat.decode(2), 'dog')\n",
    "test_stdout(lambda: show_at(tds,2), 'cat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multicategorize -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class MultiCategorize(Categorize):\n",
    "    \"Reversible transform of multi-category strings to `vocab` id\"\n",
    "    loss_func,order=BCEWithLogitsLossFlat(),1\n",
    "    def __init__(self, vocab=None, add_na=False):\n",
    "        self.add_na = add_na\n",
    "        self.vocab = None if vocab is None else CategoryMap(vocab, add_na=add_na)\n",
    "\n",
    "    def setups(self, dsets):\n",
    "        if not dsets: return\n",
    "        if self.vocab is None:\n",
    "            vals = set()\n",
    "            for b in dsets: vals = vals.union(set(b))\n",
    "            self.vocab = CategoryMap(list(vals), add_na=self.add_na)\n",
    "\n",
    "    def encodes(self, o): return TensorMultiCategory([self.vocab.o2i[o_] for o_ in o])\n",
    "    def decodes(self, o): return MultiCategory      ([self.vocab    [o_] for o_ in o])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MultiCategory(L):\n",
    "    def show(self, ctx=None, sep=';', color='black', **kwargs):\n",
    "        return show_title(sep.join(self.map(str)), ctx=ctx, color=color, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = MultiCategorize()\n",
    "tds = Datasets([['b', 'c'], ['a'], ['a', 'c'], []], tfms=[cat])\n",
    "test_eq(tds[3][0], TensorMultiCategory([]))\n",
    "test_eq(cat.vocab, ['a', 'b', 'c'])\n",
    "test_eq(cat(['a', 'c']), tensor([0,2]))\n",
    "test_eq(cat([]), tensor([]))\n",
    "test_eq(cat.decode([1]), ['b'])\n",
    "test_eq(cat.decode([0,2]), ['a', 'c'])\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class OneHotEncode(Transform):\n",
    "    \"One-hot encodes targets\"\n",
    "    order=2\n",
    "    def __init__(self, c=None): self.c = c\n",
    "\n",
    "    def setups(self, dsets):\n",
    "        if self.c is None: self.c = len(L(getattr(dsets, 'vocab', None)))\n",
    "        if not self.c: warn(\"Couldn't infer the number of classes, please pass a value for `c` at init\")\n",
    "\n",
    "    def encodes(self, o): return TensorMultiCategory(one_hot(o, self.c).float())\n",
    "    def decodes(self, o): return one_hot_decode(o, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works in conjunction with ` MultiCategorize` or on its own if you have one-hot encoded targets (pass a `vocab` for decoding and `do_encode=False` in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = OneHotEncode(c=3)\n",
    "test_eq(_tfm([0,2]), tensor([1.,0,1]))\n",
    "test_eq(_tfm.decode(tensor([0,1,1])), [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tds = Datasets([['b', 'c'], ['a'], ['a', 'c'], []], [[MultiCategorize(), OneHotEncode()]])\n",
    "test_eq(tds[1], [tensor([1.,0,0])])\n",
    "test_eq(tds[3], [tensor([0.,0,0])])\n",
    "test_eq(tds.decode([tensor([False, True, True])]), [['b','c']])\n",
    "test_eq(type(tds[1][0]), TensorMultiCategory)\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#test with passing the vocab\n",
    "tds = Datasets([['b', 'c'], ['a'], ['a', 'c'], []], [[MultiCategorize(vocab=['a', 'b', 'c']), OneHotEncode()]])\n",
    "test_eq(tds[1], [tensor([1.,0,0])])\n",
    "test_eq(tds[3], [tensor([0.,0,0])])\n",
    "test_eq(tds.decode([tensor([False, True, True])]), [['b','c']])\n",
    "test_eq(type(tds[1][0]), TensorMultiCategory)\n",
    "test_stdout(lambda: show_at(tds,2), 'a;c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class EncodedMultiCategorize(Categorize):\n",
    "    \"Transform of one-hot encoded multi-category that decodes with `vocab`\"\n",
    "    loss_func,order=BCEWithLogitsLossFlat(),1\n",
    "    def __init__(self, vocab): self.vocab,self.c = vocab,len(vocab)\n",
    "    def encodes(self, o): return TensorMultiCategory(tensor(o).float())\n",
    "    def decodes(self, o): return MultiCategory (one_hot_decode(o, self.vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = EncodedMultiCategorize(vocab=['a', 'b', 'c'])\n",
    "test_eq(_tfm([1,0,1]), tensor([1., 0., 1.]))\n",
    "test_eq(type(_tfm([1,0,1])), TensorMultiCategory)\n",
    "test_eq(_tfm.decode(tensor([False, True, True])), ['b','c'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RegressionSetup(Transform):\n",
    "    \"Transform that floatifies targets\"\n",
    "    def __init__(self, c=None): self.c = c\n",
    "    def encodes(self, o): return tensor(o).float()\n",
    "    def setups(self, dsets):\n",
    "        if self.c is not None: return\n",
    "        try: self.c = len(dsets[0]) if hasattr(dsets[0], '__len__') else 1\n",
    "        except: self.c = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_tfm = RegressionSetup()\n",
    "dsets = Datasets([0, 1, 2], RegressionSetup)\n",
    "test_eq(dsets.c, 1)\n",
    "test_eq_type(dsets[0], (tensor(0.),))\n",
    "\n",
    "dsets = Datasets([[0, 1, 2], [3,4,5]], RegressionSetup)\n",
    "test_eq(dsets.c, 3)\n",
    "test_eq_type(dsets[0], (tensor([0.,1.,2.]),))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def get_c(dls):\n",
    "    if getattr(dls, 'c', False): return dls.c\n",
    "    if getattr(getattr(dls.train, 'after_item', None), 'c', False): return dls.train.after_item.c\n",
    "    if getattr(getattr(dls.train, 'after_batch', None), 'c', False): return dls.train.after_batch.c\n",
    "    vocab = getattr(dls, 'vocab', [])\n",
    "    if len(vocab) > 0 and is_listy(vocab[-1]): vocab = vocab[-1]\n",
    "    return len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End-to-end dataset example with MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's show how to use those functions to grab the mnist dataset in a `Datasets`. First we grab all the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST_TINY)\n",
    "items = get_image_files(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we split between train and validation depending on the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#3) [Path('/home/moritz/.fastai/data/mnist_tiny/train/3/7762.png'),Path('/home/moritz/.fastai/data/mnist_tiny/train/3/8865.png'),Path('/home/moritz/.fastai/data/mnist_tiny/train/3/8012.png')],\n",
       " (#3) [Path('/home/moritz/.fastai/data/mnist_tiny/valid/3/7207.png'),Path('/home/moritz/.fastai/data/mnist_tiny/valid/3/7551.png'),Path('/home/moritz/.fastai/data/mnist_tiny/valid/3/9758.png')])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitter = GrandparentSplitter()\n",
    "splits = splitter(items)\n",
    "train,valid = (items[i] for i in splits)\n",
    "train[:3],valid[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our inputs are images that we open and convert to tensors, our targets are labeled depending on the parent directory and are categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "def open_img(fn:Path): return Image.open(fn).copy()\n",
    "def img2tensor(im:Image.Image): return TensorImage(array(im)[None])\n",
    "\n",
    "tfms = [[open_img, img2tensor],\n",
    "        [parent_label, Categorize()]]\n",
    "train_ds = Datasets(train, tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = train_ds[3]\n",
    "xd,yd = decode_at(train_ds,3)\n",
    "test_eq(parent_label(train[3]),yd)\n",
    "test_eq(array(Image.open(train[3])),xd[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAD/0lEQVR4nO2bQSh9WRzHPz+PECtlQpPNoBE1KzSKLNQ/zcLSsNSk7MQe2Q3ZWMxmlIWxMhsJJfFfCCkbkWmSWPCKFaH+GGcW73+8/zv8vTv/d697+8/vU6/Xvffce3593/f8zjn3nCfGGJQkWWEHEDVUEAcVxEEFcVBBHFQQBxXEIXRBROQPEYmLyJWI/C0iv4QaT9gDMxGpAQ6NMR9E5HvgPfCTMWYnjHhCd4gxZt8Y88Eefvx8F1Y8oQsCICK/icgt8BcQBxZDiyXsJmMRkRjwI9AC/GqMuQ8jjkg4BMAY848xZh34FugNK47ICPIJ2fxfc4iIfCMiP4tIoYjEROQd0AmshhZTmDlERIqBP4EfSPw4J8CEMeb30GKKSlKNClHMIaGigjioIA4qiEN2mutfc8aVl06qQxxUEAcVxEEFcVBBHFQQBxXEId04JCNubm4A2NvbSzk/OzsLwO3tLQDb29tP17q7u1O+8/LyggzxGeoQh3TT/4xGqs3NzQCsr6//53vLysoAODw8BAJxio5UvRBoDmloaACSDikqKgKgra3tWdn5+XkArq6uADg7OwOgo6MDgLm5uSBDfUId4hBoDnl8fARgamoKgK6uLgDy8/Oflb2+vgagvb0dgLW1tUSAkmjqm5ubANTX12cS0qdoDvFCoA75Es7PzwEoKSlJOT88PAzA4OCgX1WpQ7wQaC/zJczMzLx4vrGx8U3qV4c4RCaHHB8fA1BVVQXAw8MDkByxnpycABCLxfyqUnOIF0LJIXd3dwDE43EAtra26O1N7ICwzrAMDAwAvjrjVdQhDqHkkJ6eHgAmJyc/W6a8vBxIznazs303s+YQL4SSQ3Jzc9OWsbPdiYkJAPr7+wONyRJKk7m/T+ynW1paAmBhYYH9/X0ANjY2UsraprK8vAxAS0uLX2Fok/FCZAZmtrs9ODgAoLW1FYCLiwsAamtrAdjd3fWrSnWIFyLjEJedncRW97q6OiCZS2yuqayszLQKdYgXIjf9t1RUVKQc2xwzPT0NwMjISCD1qkMcIuuQz2FfEwSFOsThTRxyeXkJQFZWQv+CgoKU45ewrwZcfOhdXkUd4hDoOOT09BSApqYmINn+h4aGgOTLn5ycnKd7jo6OgOQSpt1KYRe37DOKi4szCQ10HOKNQB2yupr424udlzw99GOddpnSy7WxsTEg6SofUId4IdBepqamBkj2KnaLlResQ0ZHRwFfnfEq6hCHN5nt2gXsxcXE33Grq6sBWFlZAWB8fJzOzk4ACgsLAejr6wOgtLTUjxBeQnOIFyL7PuQNUId4QQVxUEEcVBAHFcRBBXFQQRzSzWVe7Ku/ZtQhDiqIgwrioII4qCAOKojDv2S5MFv0n7IOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = show_at(train_ds, 3, cmap=\"Greys\", figsize=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert ax.title.get_text() in ('3','7')\n",
    "test_fig_exists(ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ToTensor -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ToTensor(Transform):\n",
    "    \"Convert item to appropriate tensor class\"\n",
    "    order = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IntToFloatTensor -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "class IntToFloatTensor(Transform):\n",
    "    \"Transform image to float tensor, optionally dividing by 255 (e.g. for images).\"\n",
    "    order = 10 #Need to run after PIL transforms on the GPU\n",
    "    def __init__(self, div=255., div_mask=1): store_attr(self, 'div,div_mask')\n",
    "    def encodes(self, o:TensorImage): return o.float().div_(self.div)\n",
    "    def encodes(self, o:TensorMask ): return o.div_(self.div_mask).long()\n",
    "    def decodes(self, o:TensorImage): return ((o.clamp(0., 1.) * self.div).long()) if self.div else o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = (TensorImage(tensor(1)),tensor(2).long(),TensorMask(tensor(3)))\n",
    "tfm = IntToFloatTensor()\n",
    "ft = tfm(t)\n",
    "test_eq(ft, [1./255, 2, 3])\n",
    "test_eq(type(ft[0]), TensorImage)\n",
    "test_eq(type(ft[2]), TensorMask)\n",
    "test_eq(ft[0].type(),'torch.FloatTensor')\n",
    "test_eq(ft[1].type(),'torch.LongTensor')\n",
    "test_eq(ft[2].type(),'torch.LongTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "def broadcast_vec(dim, ndim, *t, cuda=True):\n",
    "    \"Make a vector broadcastable over `dim` (out of `ndim` total) by prepending and appending unit axes\"\n",
    "    v = [1]*ndim\n",
    "    v[dim] = -1\n",
    "    f = to_device if cuda else noop\n",
    "    return [f(tensor(o).view(*v)) for o in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export\n",
    "@docs\n",
    "class Normalize(Transform):\n",
    "    \"Normalize/denorm batch of `TensorImage`\"\n",
    "    parameters,order=L('mean', 'std'),99\n",
    "    def __init__(self, mean=None, std=None, axes=(0,2,3)): self.mean,self.std,self.axes = mean,std,axes\n",
    "\n",
    "    @classmethod\n",
    "    def from_stats(cls, mean, std, dim=1, ndim=4, cuda=True): return cls(*broadcast_vec(dim, ndim, mean, std, cuda=cuda))\n",
    "\n",
    "    def setups(self, dl:DataLoader):\n",
    "        if self.mean is None or self.std is None:\n",
    "            x,*_ = dl.one_batch()\n",
    "            self.mean,self.std = x.mean(self.axes, keepdim=True),x.std(self.axes, keepdim=True)+1e-7\n",
    "\n",
    "    def encodes(self, x:TensorImage): return (x-self.mean) / self.std\n",
    "    def decodes(self, x:TensorImage):\n",
    "        f = to_cpu if x.device.type=='cpu' else noop\n",
    "        return (x*f(self.std) + f(self.mean))\n",
    "\n",
    "    _docs=dict(encodes=\"Normalize batch\", decodes=\"Denormalize batch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean,std = [0.5]*3,[0.5]*3\n",
    "mean,std = broadcast_vec(1, 4, mean, std)\n",
    "batch_tfms = [IntToFloatTensor, Normalize.from_stats(mean,std)]\n",
    "tdl = TfmdDL(train_ds, after_batch=batch_tfms, bs=4, device=default_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y  = tdl.one_batch()\n",
    "xd,yd = tdl.decode((x,y))\n",
    "\n",
    "test_eq(x.type(), 'torch.cuda.FloatTensor' if default_device().type=='cuda' else 'torch.FloatTensor')\n",
    "test_eq(xd.type(), 'torch.LongTensor')\n",
    "test_eq(type(x), TensorImage)\n",
    "test_eq(type(y), TensorCategory)\n",
    "assert x.mean()<0.0\n",
    "assert x.std()>0.5\n",
    "assert 0<xd.float().mean()/255.<1\n",
    "assert 0<xd.float().std()/255.<0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "nrm = Normalize()\n",
    "batch_tfms = [IntToFloatTensor(), nrm]\n",
    "tdl = TfmdDL(train_ds, after_batch=batch_tfms, bs=4)\n",
    "x,y  = tdl.one_batch()\n",
    "test_close(x.mean(), 0.0, 1e-4)\n",
    "assert x.std()>0.9, x.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Just for visuals\n",
    "from fastai2.vision.core import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAElklEQVR4nO2bb2jUdRzHX5/b4UTag7Yc2dZSh2ZozfVkzWrbE1uzjECDxAcipCW0WbAgRjArkGJR/qk9yMiKoVg9y+lEUmmyhBqr2Ci0PxsSttyyKbXZdvftwffOdR9tO+3ufld9XjB2u9/3bh/ev9fv+/v+uRPnHMYkoaALyDYsEIUForBAFBaIwgJRWCCKwAMRkTYROSMi50XkpIg8Fmg9QQ/MRGQx8K1z7qKILAKOAQ8457qDqCdwQ5xzfc65i/E/Yz+lQdUTeCAAItIqIr8D3wBngAOB1RL0JRNHRHKASqAGeNk5Nx5EHVlhCIBzLuKcOw4UA5uCqiNrAvkLYf6vfYiIFIrIoyJynYjkiEgtsAY4ElhNQfYhIjIb+BAow5+cAWCHc25XYDVlS6eaLWRjHxIoFojCAlFYIIrwVAeXhx75z/a4h6MfyJWeN0MUFojCAlFYIAoLRGGBKCwQxZTjkGslWl0OwJyXvgPgRP88APqq3k5o1/yzb7f38wqKOvy5yWv/0r/H2Fg6SpsWM0SRFkN+uXUmAPtLPgYgVOJzjxJNaNdc6Hcanl/RQ3SFP3ZbVT0ACzafSEdp02KGKNJiSN7pCQDu6VmbVPuu8r2XHu9Z+QYAL776MAATA6dTXN3UmCGKtBiSe/Cz2O/k2pc/W093/Xb/ONf3JS53RjpKmxYzRJEWQ6YjlJcHwPCqJQD0NrQy7vy52Tp0u280fC6I0swQTSCG9D/tLfjicd9vjLsQP0z4ken+bdUA5A9/GkRpZogmo4ac2lkBQMdDLbFn/J1kMDLK2i3PAJC/Oxgz4pghiowYklOQD8C6qk4AbgknjjFWNzWS3xasGXHMEEVGDImUFgHQdMPh2DP+PJTv9DPborauTJSRFGaIIiOGnNzg10f0ekh8/lJdtYbRQ4UAzDk+AoDr7stEaZeRkUAW7P4DgIM11wNQNytxWN5Zto9omQ+rZ7OX9r3hu32BEgFgwuUAcPSjOwEoPjoKQKizJ6W12iWjmPITRKne7HbLygA4tc7fdg/dvw2AeeGZl11OcUJceflxYMJbt2l9AwDhI1f3wWfb7E6SjBryd+QU5PN9wyIAxkt93/BaxT5/TLwZkdjyQFH4VwDumOH7lE/GvG2vLF0GQPTChaT+pxmSJFlhyNUwtLESgK7mHcBkH1O55UkACnYlNwUwQ5IkkAWiayFcdBMAi9cnDtgGI77PiW99/FPMEEXWGzLwgu8z7q39CoDXi48lHK95vxGA0o7UbH2aIYqMGvLTU36sQOzedeP2yWl/vI8YuetmAOY3fg3AgRK/tRmNvWgw4r+NtropZkZbajfFzRBFRg3JXX4WgKaFfo9z6311l449t7AdgNpZIwmvicbO2ZsjcwF4p+VBgLQtOZohikDuMvH1kLqlewA/2tSz2bdG5gPQ2rYSgLnv9gOQ/2N6F6PNEEVGDZm98TcAlrRsAKC32n+TbGH7ExTHP3TXO+QbnzsPQPFZfydKzTh0eswQxb9utpsqbLabJBaIwgJRWCAKC0RhgSgsEIV9919hhigsEIUForBAFBaIwgJR/Am8yzseXl6iEAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAE50lEQVR4nO2bX2wUVRSHv9PtYpu1lRSKIipICy1FBCFBW6KIRCGRSKKiFKIxCipoJPEFDYI8oIYQQ5UIGAkP8udBlGhQjBINRiPVWBSR8MdSRYpNFBSpgS509/pwt6inSzVst3ej50uaTefuzJ785ps7d+7MiHMO40/yQheQa1ggCgtEYYEoLBCFBaKwQBTBAxGR9SLSIiInROSAiMwKWk/ogZmIDAcanXNxEakEtgO3OucaQtQT3BDn3B7nXLzj39RfWah6ggcCICIrReQksA9oAbYGqyX0IdOBiESAauBGYKlz7kyIOnLCEADnXMI59wlwGTAnVB05E8hfyOf/2oeISD8RmS4iF4pIREQmAbXAh8FqCtmHiEgp8DowEr9zDgEvOudeCVZTrnSquUIu9iFBsUAUFojCAlHkd9V4c960/2yPuy25SdItN0MUFojCAlFYIAoLRGGBKCwQhQWisEAUFojCAlF0eS3Tk+T3vwSAxrlXAhAZ1grA4qu3AHBH7Ne06604PhiA92ZUA5DctTejOswQRU4YEhlaRtnGHwB4s/87ab+TTH3GU7drPm0rAuCR3gcBGLH5MADzn3sQgD5rdpxXLWaIokcNkXz/c79PHQNAyWOHAFgycAPDo70AiLsEAEuPXQPA+q/HAjDgjSgA0VbfXrCvBYBR9ZsAuKHA/4aLZFajGaLoUUO+X+j39u5ZK1RLlCVHrwJg49vjARi0wPcB5XyZdluu3J+N9B49XZx2IuxfY4YosmqIqxkJwIy17wIwJbYs1eIP+Kd+8n3J9uXVlLzmTRjU1vXZ4ec5fryx6Qm/rYvyCgGoWv8oAGV1X/jfPs+azRBFVg1pGRcDYGZRS2qJN6Nqg9+b5Yu8Fb3bdpwdZ2gifUoA+G71AAC2XevNuDjizXj26Ai/raf9tpJnTmdUsxmiyKohl289BkDN+FoATn3cF4DByz4DIJlMnHPd5idrAFj+gH8QYEJhW6rFm/HwYX82anymCoCCts+7pWYzRJFVQxJ79gNQMqVjyYF/XOfbV0cD8M1NdQBE5e9Dz9Wpq9vmmlMAFCS7x4wOgl7cdQzlD9SNYcHEtwC4s+glACLi2+b9OA6AxnkVAEQP+8OQZHNWarJDRhHUkEip72RXT17LxEL/7G4Sf5E3Yfc0AGKTmwAQdgHQnuWazBBFUENOXDcQgImFcSLi903lOv+I6uD55zfBkylmiCJoILEtDcS2NDBk8xwSLknCJWkvStBedO4BW7YxQxRB+xDX7s8Z/eoFbvfLKiqP+LZANZkhiqCG5MX89EDhfS1nlxX38hdxvwWpyAzpRFBD9i/1E8v7q1YCfnK4dW5pqvVYkJrMEEWPGhLp2weAfQuHAFA/9flUSwF3N90CgNvb1JMldcIMUWRkSP6gKwD4peZSAIo31qf93vF7/a2DZYtXAVB9wfupFj/pXNs0idbrj2ZSSrdhhigyMqRtjf98udxP991V8TgAsSN+nJl3mz9TfDTqBaDzdGDFB7MBGDp7TyZldCtmiCIjQ4b39iPMYVH/qELnm9gdeDMaUi+0L5p5PwBDd3ozXDyedq0QmCGKjAw5OMXfZhy96h4Ado5dl/Z7476aDkDpQycBkGY/P5qLbyeZIYou39u1V8wMC0RjgSjs3X+FGaKwQBQWiMICUVggCgtE8QcHRC/xvameTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAD8klEQVR4nO2bX2iVZRzHP79tNtYUNZyIuYF/mpLmdlFMpegPSMiYCBb4r11NyaUkKEU3RRchLqk0M6LYTSMIs9I4gkSWf9CRuEKRyhW6CzVXZumWHredp4vnnKm/U3MXp+d5qd8HBuc873vgy/d83ud93+c9E+ccxg2KYgdIGlaIwgpRWCEKK0RhhSisEEX0QkSkTUTOi8hlETklIk1R88S+MBORmcCPzrm0iMwAvgLqnXPHYuSJbohz7qRzLp17m/2bGitP9EIARGS7iPwJfA+cB/ZEyxL7kMkhIsXAXOARYJNzri9GjkQYAuCcG3DOHQImAatj5UhMITdRwv91DhGR8SKyRERGikixiDwOLAX2RcsUcw4RkQrgI6AG/+V0AVudc+9Gy5SUSTUpJHEOiYoVorBCFFaIomSojfOLnvzPzrifZ3bI342bIQorRGGFKKwQhRWisEIUVojCClFYIQorRGGFKIa8lyk4c2YD8NMTdwLw0IMnATh4aObgLmUX/Hc08dXDQaPlMEMUQQ1Z2PolAE+P7rplvHjZQQZcBoAM/ga7eop/ElG9+uuACc2QPIZcZC74esgXkwA4dWZC3qaKCX8AcKT2QwD6GQBgV+84AFqXLwTAHT1RkCi2HjJMgs4h3TurAKju6PED7ccHt8mIOwC45w0/d3QuehuAxeWXANhYNwqA8Uf/3YxmiCLoHFJUXg6Au+4f7Lu+6/mBSksB6GmoBWD/Fm/K5t+mA7DvvvKCZLE5ZJgEnUMyvb233cel/Y+Jfl/Wc8t46twsAMo4XfhgN2GGKMLeywyD7uZ5AOy5vwWAM/1+XLZVZPcwQ4KSGEO6n/FmfPycN+Oa8yeB5S9vAOCuz44EyRG1kJJKfyl/urGK1CpfRB++iAUH1gAwrTVMETnskFFEMeTndf7waFqZAqB5zG7ALxrVbsma0WILRIkgiiErmvYC0Dwm/xRa9vAv/kVLyEQ3MEMUUQxJPf8YAJ+Mmg/ArzXCd41vAfDoxE4Avo0RDDMkjyiGlKb8Kk9p9n1RXx00+te7P/VnoCrsLJMIEnHpfmFxevD12B8yEZOYIXlENaRzax0AH8zZzqXMNR/oqhmSKIIakltkvrLALwfuaHgTgParU1n3Yj0Ao3e1h4yUhxmiCGrIuVU1AHRs2AZAj/OPK596r4HKtjjXHRozRBHEkHT9AwC8/+xr2RH/2HLuO+sBqHwlGXaAGZJHEEPWvu5/4jB9RDEAGy/eC8DktrMA9IcIMUzMEEUQQ17oWATAS9+MBODuTbk5o+sfPhEPM0QRxJDJS47ffqeEYIYorBCFFaKw//1XmCEKK0RhhSisEIUVorBCFH8ByOr0HigOc5QAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABUCAYAAAA7xZEpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAEa0lEQVR4nO2bf2hVZRjHP8/ucl6di2yZLWtl7uqyIVIpTUn/cMyQEgSpiKhBNIyQ6o9+gP9EZKj/5GD7J8qCIFlRLKKQNCIyTSnMWtQq1wZrTVrgtW1t3nvf/ni92+6zu3Vr99xzqecDF+55z3vuefi+3/Pc933OOeKcw5igJOwAig0TRGGCKEwQhQmiMEEUJogidEFE5HUR6ReRuIh0ichDocYT9sRMRFYCPzrnRkVkBfAxsMU590UY8YTuEOdcp3NuNL158XNDWPGELgiAiLSJyDDwHdAPvB9aLGFfMmlEJALcBmwE9jjnLoQRR1E4BMA5l3TOfQosAXaEFUfRCDKJUv6vOUREFonIPSJSLiIREWkE7gU+Ci2mMHOIiFwBvAWswg9OD9DinHsptJiKJakWC8WYQ0LFBFGYIAoTRFE6086Gku3/2Yz7YepNydZuDlGYIAoTRGGCKEwQhQmiMEEUM85DZv3j1dcAMNCwJKN9ePN5AMqjvpR6/3Unxve9eOgOAFbs7QYg8etAkCFOwRyimHH5P9uZav1XYwDsqvzmHx97dNSP1Z76RiD/TrGZao4EmkMOdt0MTDik84J3zNPd26b0bV3aDsC1pfMAWFeWAqCq4w8AetcGGekE5hBFoDlESr0Bf3r+VgBiLT0AJPp+mdK39PpqAG562/fZvehLAFL4EOp3PQrAwgPHZhPSOJZDciTQHOISCQCWPuVHNTFD30S3d8ap5jrf8I53SAl+IAc3+Pyz8EAAgU7CHKII1CH/hh8emJe1vfx0WUHObw5RFI1DxhpvAeD01v0XW+YAEzPWqlb//EzQRV5ziCIUh0QqKgD4c00NAP3ry+ho2gdAVKIZfR/8oBmAmtHPCxKbOUQRikPOtVcC8End5Jv8mc44MuL/VZY/6ddBqYJEZg6ZQigOGRm75G/71M/1VbXmfSsBiD1yYqbueSPQxd10lMyfD0DvzlUAVNw+wJarOwF45vJvM/qOOD9lX7/3CQCubPksLzHY4i5HQnFINtKuOXenX9y1veAnaHVz/OX1arwKgPbaxXk5nzkkR4pm6p4aGgJgwcHjADxc9hgAx3a3AnD3gp8BeG3rXQBEO4JJsuYQRdE4RFN5cjBjOyp+sde33T/xvawjmPOaQxRF65DpqKk6CwRXBjCHKArikMiNMf9lzF//yTO9fjuVnPaYeO1lWdu/7/HzkBh9+QtwEuYQRaAOSW1YDcDOl98AYHN0GICaw/49w9pnfwfAxc+PHxPfuAyApucy/0YGUyMALG/zaxvLIQUiUIecXe2LPmlnpDnT8AoAyU1Tyz4ROeL3ucx9a997HIDYyWDLAOYQRaAOWXzcP8rQn/QOuSqS/SZUNtI3uWPv+tfvYjsKUyAyhygKUw9Z42sc3dvKAbi0yzf/ts7PSw5t2s99XzcBEB+aC0B1ix8rOXoqLyForB6SI0VTMSs05pAcMUEUJojCBFGYIAoTRGGCKOzdf4U5RGGCKEwQhQmiMEEUJojiL4QhMZIcv2YkAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tdl.show_batch((x,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x,y = torch.add(x,0),torch.add(y,0) #Lose type of tensors (to emulate predictions)\n",
    "test_ne(type(x), TensorImage)\n",
    "tdl.show_batch((x,y), figsize=(4,4)) #Check that types are put back by dl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: make the above check a proper test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 00_torch_core.ipynb.\n",
      "Converted 01_layers.ipynb.\n",
      "Converted 02_data.load.ipynb.\n",
      "Converted 03_data.core.ipynb.\n",
      "Converted 04_data.external.ipynb.\n",
      "Converted 05_data.transforms.ipynb.\n",
      "Converted 06_data.block.ipynb.\n",
      "Converted 07_vision.core.ipynb.\n",
      "Converted 08_vision.data.ipynb.\n",
      "Converted 09_vision.augment.ipynb.\n",
      "Converted 09b_vision.utils.ipynb.\n",
      "Converted 09c_vision.widgets.ipynb.\n",
      "Converted 10_tutorial.pets.ipynb.\n",
      "Converted 11_vision.models.xresnet.ipynb.\n",
      "Converted 12_optimizer.ipynb.\n",
      "Converted 13_callback.core.ipynb.\n",
      "Converted 13a_learner.ipynb.\n",
      "Converted 13b_metrics.ipynb.\n",
      "Converted 14_callback.schedule.ipynb.\n",
      "Converted 14a_callback.data.ipynb.\n",
      "Converted 15_callback.hook.ipynb.\n",
      "Converted 15a_vision.models.unet.ipynb.\n",
      "Converted 16_callback.progress.ipynb.\n",
      "Converted 17_callback.tracker.ipynb.\n",
      "Converted 18_callback.fp16.ipynb.\n",
      "Converted 19_callback.mixup.ipynb.\n",
      "Converted 20_interpret.ipynb.\n",
      "Converted 20a_distributed.ipynb.\n",
      "Converted 21_vision.learner.ipynb.\n",
      "Converted 22_tutorial.imagenette.ipynb.\n",
      "Converted 23_tutorial.vision.ipynb.\n",
      "Converted 24_tutorial.siamese.ipynb.\n",
      "Converted 30_text.core.ipynb.\n",
      "Converted 31_text.data.ipynb.\n",
      "Converted 32_text.models.awdlstm.ipynb.\n",
      "Converted 33_text.models.core.ipynb.\n",
      "Converted 34_callback.rnn.ipynb.\n",
      "Converted 35_tutorial.wikitext.ipynb.\n",
      "Converted 36_text.models.qrnn.ipynb.\n",
      "Converted 37_text.learner.ipynb.\n",
      "Converted 38_tutorial.ulmfit.ipynb.\n",
      "Converted 40_tabular.core.ipynb.\n",
      "Converted 41_tabular.data.ipynb.\n",
      "Converted 42_tabular.model.ipynb.\n",
      "Converted 43_tabular.learner.ipynb.\n",
      "Converted 45_collab.ipynb.\n",
      "Converted 50_tutorial.datablock.ipynb.\n",
      "Converted 60_medical.imaging.ipynb.\n",
      "Converted 61_tutorial.medical_imaging.ipynb.\n",
      "Converted 65_medical.text.ipynb.\n",
      "Converted 70_callback.wandb.ipynb.\n",
      "Converted 71_callback.tensorboard.ipynb.\n",
      "Converted 72_callback.neptune.ipynb.\n",
      "Converted 97_test_utils.ipynb.\n",
      "Converted 99_pytorch_doc.ipynb.\n",
      "Converted index.ipynb.\n",
      "Converted tutorial.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "split_at_heading": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
